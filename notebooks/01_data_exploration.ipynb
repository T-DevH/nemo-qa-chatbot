{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration for NeMo QA Chatbot\n",
    "\n",
    "This notebook explores the data curation process for the NeMo QA Chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import NeMo QA modules\n",
    "from nemo_qa.curator.document_processor import process_documents\n",
    "from nemo_qa.curator.qa_generator import generate_qa_pairs\n",
    "from nemo_qa.curator.quality_filters import filter_qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Documents\n",
    "\n",
    "Let's load the raw documents and explore their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with your data path\n",
    "data_dir = '../data/raw'\n",
    "\n",
    "# List documents\n",
    "documents = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.json') or filename.endswith('.jsonl'):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            if filename.endswith('.json'):\n",
    "                doc = json.load(f)\n",
    "                documents.append(doc)\n",
    "            else:\n",
    "                for line in f:\n",
    "                    doc = json.loads(line.strip())\n",
    "                    documents.append(doc)\n",
    "\n",
    "print(f'Loaded {len(documents)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Statistics\n",
    "\n",
    "Let's analyze the statistics of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate document statistics\n",
    "doc_stats = pd.DataFrame({\n",
    "    'document_id': [i for i in range(len(documents))],\n",
    "    'text_length': [len(doc.get('text', '')) for doc in documents]\n",
    "})\n",
    "\n",
    "# Plot document length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(doc_stats['text_length'], bins=20)\n",
    "plt.title('Document Length Distribution')\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Mean document length: {doc_stats['text_length'].mean():.2f} characters\")\n",
    "print(f\"Median document length: {doc_stats['text_length'].median():.2f} characters\")\n",
    "print(f\"Min document length: {doc_stats['text_length'].min()} characters\")\n",
    "print(f\"Max document length: {doc_stats['text_length'].max()} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents\n",
    "\n",
    "Now let's process the documents using the document processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_dir = '../data/processed'\n",
    "\n",
    "# Define filters\n",
    "filters = [\n",
    "    {\n",
    "        'name': 'length_filter',\n",
    "        'min_length': 100,\n",
    "        'max_length': 2000\n",
    "    },\n",
    "    {\n",
    "        'name': 'language_filter',\n",
    "        'languages': ['en']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process documents\n",
    "stats = process_documents(\n",
    "    input_dir=data_dir,\n",
    "    output_dir=processed_dir,\n",
    "    filters=filters\n",
    ")\n",
    "\n",
    "print(f\"Processed {stats['input_files']} documents to {stats['output_files']} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Q&A Pairs\n",
    "\n",
    "Now let's generate Q&A pairs from the processed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "qa_dir = '../data/qa_pairs'\n",
    "\n",
    "# Generate Q&A pairs\n",
    "qa_pairs = generate_qa_pairs(\n",
    "    model_path='models/base/llama3-8b',\n",
    "    input_dir=processed_dir,\n",
    "    output_dir=qa_dir,\n",
    "    question_template=\"Generate a detailed question based on this text: {text}\",\n",
    "    answer_template=\"Answer the following question based on this text:\\nQuestion: {question}\\nText: {text}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(qa_pairs)} Q&A pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Q&A Pairs\n",
    "\n",
    "Let's analyze the generated Q&A pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to DataFrame\n",
    "qa_df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Add length columns\n",
    "qa_df['question_length'] = qa_df['question'].apply(len)\n",
    "qa_df['answer_length'] = qa_df['answer'].apply(len)\n",
    "\n",
    "# Plot question and answer length distributions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "sns.histplot(qa_df['question_length'], bins=20, ax=ax[0])\n",
    "ax[0].set_title('Question Length Distribution')\n",
    "ax[0].set_xlabel('Question Length (characters)')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "sns.histplot(qa_df['answer_length'], bins=20, ax=ax[1])\n",
    "ax[1].set_title('Answer Length Distribution')\n",
    "ax[1].set_xlabel('Answer Length (characters)')\n",
    "ax[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Mean question length: {qa_df['question_length'].mean():.2f} characters\")\n",
    "print(f\"Mean answer length: {qa_df['answer_length'].mean():.2f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Q&A Pairs\n",
    "\n",
    "Now let's filter the Q&A pairs based on quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "filtered_dir = '../data/qa_pairs/filtered'\n",
    "\n",
    "# Filter Q&A pairs\n",
    "filtered_pairs = filter_qa_pairs(\n",
    "    qa_pairs=qa_pairs,\n",
    "    output_dir=filtered_dir,\n",
    "    min_question_length=10,\n",
    "    max_question_length=200,\n",
    "    min_answer_length=50,\n",
    "    max_answer_length=1000,\n",
    "    min_relevance_score=0.3,\n",
    "    diversity_clusters=10\n",
    ")\n",
    "\n",
    "print(f\"Filtered from {len(qa_pairs)} to {len(filtered_pairs)} Q&A pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Splits\n",
    "\n",
    "Finally, let's create the dataset splits for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create dataset splits\n",
    "train_pairs, temp_pairs = train_test_split(\n",
    "    filtered_pairs, test_size=0.2, random_state=42\n",
    ")\n",
    "val_pairs, test_pairs = train_test_split(\n",
    "    temp_pairs, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_pairs)} pairs\")\n",
    "print(f\"Validation set: {len(val_pairs)} pairs\")\n",
    "print(f\"Test set: {len(test_pairs)} pairs\")\n",
    "\n",
    "# Save dataset splits\n",
    "datasets_dir = '../data/datasets'\n",
    "os.makedirs(datasets_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(datasets_dir, 'train.jsonl'), 'w') as f:\n",
    "    for pair in train_pairs:\n",
    "        f.write(json.dumps(pair) + '\\n')\n",
    "\n",
    "with open(os.path.join(datasets_dir, 'val.jsonl'), 'w') as f:\n",
    "    for pair in val_pairs:\n",
    "        f.write(json.dumps(pair) + '\\n')\n",
    "\n",
    "with open(os.path.join(datasets_dir, 'test.jsonl'), 'w') as f:\n",
    "    for pair in test_pairs:\n",
    "        f.write(json.dumps(pair) + '\\n')\n",
    "\n",
    "print(f\"Dataset splits saved to {datasets_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
